
% For making text flow around images:
\usepackage{wrapfig}

% For random text:
\usepackage{blindtext}

% For pdf graphics:
\usepackage{pdfpages} 

% For quoting:
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}

% For citations with a title:
%\usepackage{biblatex}

% For compact lists:
\usepackage{paralist}

% Two equations next to each other:

\usepackage{multicol}

% For crossed out stuff! (\xcancel)

\usepackage{cancel}
 

% End of imports!

\kurzfassung{ 

    In dieser Arbeit wird der momentane Stand der Technik im
    Bereich des \textit{Deep Learning} thematisiert.
    Konkret werden
    künstliche neuronale Netzwerken
    in Bezug auf den Aufbau der Rechengraphen als auch 
    ihrer Lernstrategien untersucht, um häufig vorkommende Architekturmuster zu identifizieren.
    Das Ziel ist hierbei diese Architektur Muster 
    im Hinblick auf biologoische neuronale Netzwerke zu untersuchen um
    mögliche Herausforderungen im momentanen Stand der Technik aufdecken zu können.
    Darauf aufbauend werden \textit{bedingte neuronale Netzwerke (conditional neural networks)} untersucht, eine
    Kategorie von neuronalen Netzwerken mit
    dem Potential die identifizierten Probleme
    in dem Bereich des Deep Learning zu lösen.
    Zudem werden aktuelle Probleme identifiziert mit denen
    bedingte neuronale Netze konfrontiert sind.
    Anhand der daraus gewonnenen Erkenntnisse stellt diese Arbeit
    eine eigene bedingte NN Architektur vor
    um diese in darauffolgenden Kapiteln auf die besprochenen Vor- und Nachteile zu testen.
    
 
}
\schlagworte{
        Maschinelles Lernen, 
        Tiefes Lernen,
        Neuronale Netzwerke,
        Bedingte Neuronale Netzwerke, 
        Künstliche Intelligenz,
        Rechengraphen,
        KI
    }

\outline{ 
    This work discusses the current state of the art in
    the area of \textit {Deep Learning}.
    It examines artificial neural networks 
    with respect to the structure of their computation graphs as well as commonly used learning strategies in order to identify common architectural design patterns.
    The goal is to distinctly identify those architectural patterns
    which represent discrepancies compared to biological neural networks to investigate
    and uncover possible challenges in current state of the art
    design choices.
    On this basis \textit{conditional neural networks} will be discussed. 
    They are a special category of neural networks with the potential 
    to overcome these challenges in the field of deep learning. 
    Additionally the thesis discusses the challenges which are 
    faced by current state of the art conditional neural networks. 
    Furthermore a custom conditional neural network architecture is
    introduced which was tested on the discussed advantages and disadvantages.
}

\keywords{
        Machine Learning, 
        Deep Learning,
        Neural Networks,
        Conditional Neural Networks,
        Sparsity,
        Artificial Intelligence,
        Computation Graph,
        Online Learning,
        AI
}

\acknowledgements{ 
    I hereby want to thank my partner
    Emily Riemer for supporting me throughout the making of this thesis.
    I also want to express my sincere gratitude to
    Jenny Gebauer, Oliver Schweigler, MSc Markus Petz and DI Harald Demel for proofreading this thesis while also providing helpful advice and feedback.
    Lastly I want to acknowledge my cat Hailey for sharing her calm aura with me during stressful times.
}

